{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# import the libraries\r\n",
    "import torch\r\n",
    "from torch import nn\r\n",
    "from torchvision import transforms\r\n",
    "from torchvision.datasets import MNIST\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torchvision.utils import make_grid\r\n",
    "from torchviz import make_dot\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from torchvision.utils import make_grid"
   ],
   "outputs": [],
   "metadata": {
    "gradient": {}
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
    "print(f\"Using {device} device\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# use if IProgress bar error comes\r\n",
    "#!pip install ipywidgets\r\n",
    "#!jupyter nbextension enable --py widgetsnbextension"
   ],
   "outputs": [],
   "metadata": {
    "gradient": {}
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# generator network class\r\n",
    "class Generator(nn.Module):\r\n",
    "    def __init__(self,z_dim = 10, img_dim = 784 , hidden_dim = 128):\r\n",
    "        super().__init__()\r\n",
    "        self.linear1     = nn.Linear(z_dim,hidden_dim)\r\n",
    "        self.batch1      = nn.BatchNorm1d(hidden_dim)\r\n",
    "\r\n",
    "        self.linear2     = nn.Linear(hidden_dim,hidden_dim*2)\r\n",
    "        self.batch2      = nn.BatchNorm1d(hidden_dim*2)\r\n",
    "\r\n",
    "        self.linear3     = nn.Linear(hidden_dim*2,hidden_dim*4)\r\n",
    "        self.batch3      = nn.BatchNorm1d(hidden_dim*4)\r\n",
    "\r\n",
    "        self.linear4     = nn.Linear(hidden_dim*4,hidden_dim*8)\r\n",
    "        self.batch4      = nn.BatchNorm1d(hidden_dim*8)\r\n",
    "        \r\n",
    "        self.output      = nn.Linear(hidden_dim*8,img_dim)\r\n",
    "        self.activation  = nn.ReLU(inplace=True)\r\n",
    "        self.out_act     = nn.Sigmoid()\r\n",
    "        \r\n",
    "    def forward(self,alpha):\r\n",
    "        alpha = self.linear1(alpha)\r\n",
    "        alpha = self.batch1(alpha)\r\n",
    "        alpha = self.activation(alpha)\r\n",
    "\r\n",
    "        alpha = self.linear2(alpha)\r\n",
    "        alpha = self.batch2(alpha)\r\n",
    "        alpha = self.activation(alpha)\r\n",
    "\r\n",
    "        alpha = self.linear3(alpha)\r\n",
    "        alpha = self.batch3(alpha)\r\n",
    "        alpha = self.activation(alpha)\r\n",
    "\r\n",
    "        alpha = self.linear4(alpha)\r\n",
    "        alpha = self.batch4(alpha)\r\n",
    "        alpha = self.activation(alpha)\r\n",
    "\r\n",
    "        return self.out_act(self.output(alpha))\r\n"
   ],
   "outputs": [],
   "metadata": {
    "gradient": {}
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# discriminator network  \r\n",
    "class Discriminator(nn.Module):\r\n",
    "    def __init__(self, img_dim = 784 , hidden_dim = 128):\r\n",
    "        super().__init__()\r\n",
    "        self.linear1    = nn.Linear(img_dim,hidden_dim*4)\r\n",
    "        self.linear2    = nn.Linear(hidden_dim*4,hidden_dim*2)\r\n",
    "        self.linear3    = nn.Linear(hidden_dim*2,hidden_dim)\r\n",
    "        self.output     = nn.Linear(hidden_dim,1)\r\n",
    "        self.activation = nn.LeakyReLU(0.2)\r\n",
    "        \r\n",
    "    def forward(self,alpha):\r\n",
    "        alpha = self.activation(self.linear1(alpha))\r\n",
    "        alpha = self.activation(self.linear2(alpha))\r\n",
    "        alpha = self.activation(self.linear3(alpha))\r\n",
    "        return self.output(alpha)"
   ],
   "outputs": [],
   "metadata": {
    "gradient": {}
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# global parameters\r\n",
    "n_epochs   = 100\r\n",
    "noise_dim  = 64\r\n",
    "batch_size = 128\r\n",
    "img_dim    = 784\r\n",
    "lr = 0.0001"
   ],
   "outputs": [],
   "metadata": {
    "gradient": {}
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load the dataset\r\n",
    "dataloader = DataLoader(MNIST('.',download=True,transform=transforms.ToTensor()),\r\n",
    "                       batch_size = batch_size,shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# generator and discriminator optimizers and networks\r\n",
    "gen_network = Generator(z_dim=noise_dim).to(device)\r\n",
    "disc_network = Discriminator().to(device)\r\n",
    "\r\n",
    "gen_opt  = torch.optim.Adam(gen_network.parameters(),lr = lr)\r\n",
    "disc_opt = torch.optim.Adam(disc_network.parameters(),lr = lr)\r\n",
    "\r\n",
    "# loss function\r\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ],
   "outputs": [],
   "metadata": {
    "gradient": {}
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# function to print the network\r\n",
    "temp_inp = torch.rand(batch_size,noise_dim,device=device)\r\n",
    "y_hat = gen_network(temp_inp)\r\n",
    "make_dot(y_hat, params=dict(list(gen_network.named_parameters()))).render(\"gen_torchviz1\", format=\"png\")\r\n",
    "\r\n",
    "temp_inp = torch.rand(batch_size,img_dim,device=device)\r\n",
    "y_hat = disc_network(temp_inp)\r\n",
    "make_dot(y_hat, params=dict(list(disc_network.named_parameters()))).render(\"disc_torchviz1\", format=\"png\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'disc_torchviz1.png'"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "def disp_imgs(img_out):\r\n",
    "    disp_img = img_out.detach().cpu().view(-1,1,28,28)\r\n",
    "    img_grid = make_grid(disp_img[:25],nrow=5)\r\n",
    "    plt.imshow(img_grid.permute(1,2,0).squeeze())\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "# training loop\r\n",
    "gen_meanloss  = 0\r\n",
    "disc_meanloss = 0\r\n",
    "cur_step  = 0\r\n",
    "for epoch in range(n_epochs):\r\n",
    "    for real_imgs,_ in dataloader:\r\n",
    "        cur_step+=1\r\n",
    "        cur_batch_size = len(real_imgs)\r\n",
    "        # flattenning the images\r\n",
    "        real_imgs = real_imgs.view(cur_batch_size,-1).to(device)\r\n",
    "        \r\n",
    "        # training the discriminator\r\n",
    "        disc_opt.zero_grad()\r\n",
    "        gen_noise  = torch.randn(cur_batch_size,noise_dim,device=device)\r\n",
    "        gen_images = gen_network(gen_noise)\r\n",
    "        disc_out1   = disc_network(gen_images.detach())\r\n",
    "        disc_loss  = criterion(disc_out1,torch.zeros_like(disc_out1))\r\n",
    "        disc_out2   = disc_network(real_imgs)\r\n",
    "        disc_loss += criterion(disc_out2,torch.ones_like(disc_out2))\r\n",
    "        disc_loss /= 2\r\n",
    "        disc_loss.backward(retain_graph=True)\r\n",
    "        disc_opt.step()\r\n",
    "        \r\n",
    "        # training the generator\r\n",
    "        gen_opt.zero_grad()\r\n",
    "        gen_noise  = torch.randn(cur_batch_size,noise_dim,device=device)\r\n",
    "        gen_images = gen_network(gen_noise)\r\n",
    "        disc_out   = disc_network(gen_images)\r\n",
    "        gen_loss  = criterion(disc_out,torch.ones_like(disc_out))\r\n",
    "        gen_loss.backward()\r\n",
    "        gen_opt.step()\r\n",
    "        gen_meanloss  += gen_loss.item()\r\n",
    "        disc_meanloss += disc_loss.item()\r\n",
    "        if cur_step%500 == 0:\r\n",
    "            print(\" Current Step: \"+str(cur_step))\r\n",
    "            print(\" Generator loss     : \"+str(gen_meanloss/cur_step))\r\n",
    "            print(\" Discriminator loss : \"+str(disc_meanloss/cur_step))\r\n",
    "            gen_noise  = torch.randn(cur_batch_size,noise_dim,device=device)\r\n",
    "            img_out = gen_network(gen_noise)\r\n",
    "            disp_imgs(img_out=img_out)\r\n",
    "            disp_imgs(img_out=real_imgs)"
   ],
   "outputs": [],
   "metadata": {
    "gradient": {}
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('pytorch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "5d855df8f7145eb226b62743acd8e28102a2a44e3ee1c88c6c9f00d00081662c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}